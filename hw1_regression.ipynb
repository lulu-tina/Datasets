{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw1_regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lulu-tina/Datasets/blob/master/hw1_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9FfatPz6MU3"
      },
      "source": [
        "# **Homework 1: Linear Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsoaNwrZA0ui"
      },
      "source": [
        "本次目標：由前 9 個小時的 18 個 features (包含 PM2.5)預測的 10 個小時的 PM2.5。<!-- 可以參考 <link> 獲知更細項的作業說明。-->\n",
        "\n",
        "<!-- 首先，從 https://drive.google.com/open?id=1El0zvTkrSuqCTDcMpijXpADvJzZC2Jpa 將整個資料夾下載下來，並將下載下來的資料夾放到自己的 Google Drive（注意：上傳到自己 Google Drive 的是資料夾 hw1-regression，而非壓縮檔） -->\n",
        "\n",
        "\n",
        "若有任何問題，歡迎來信至助教信箱 ntu-ml-2020spring-ta@googlegroups.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7RiAkkjCc6l"
      },
      "source": [
        "# **Load 'train.csv'**\n",
        "train.csv 的資料為 12 個月中，每個月取 20 天，每天 24 小時的資料(每小時資料有 18 個 features)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AfNX-hB3kN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a261f349-545c-40f7-c296-566650de8482"
      },
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive \n",
        "!gdown --id '1wNKAxQ29G15kgpBy_asjTcZRRgmsCZRm' --output data.zip\n",
        "!unzip data.zip\n",
        "# data = pd.read_csv('gdrive/My Drive/hw1-regression/train.csv', header = None, encoding = 'big5')\n",
        "data = pd.read_csv('./train.csv', encoding = 'big5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wNKAxQ29G15kgpBy_asjTcZRRgmsCZRm\n",
            "To: /content/data.zip\n",
            "100% 177k/177k [00:00<00:00, 1.57MB/s]\n",
            "Archive:  data.zip\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqUdj00pDTpo"
      },
      "source": [
        "# **Preprocessing** \n",
        "取需要的數值部分，將 'RAINFALL' 欄位全部補 0。\n",
        "另外，如果要在 colab 重覆這段程式碼的執行，請從頭開始執行(把上面的都重新跑一次)，以避免跑出不是自己要的結果（若自己寫程式不會遇到，但 colab 重複跑這段會一直往下取資料。意即第一次取原本資料的第三欄之後的資料，第二次取第一次取的資料掉三欄之後的資料，...）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIGP7XUYD_Yb"
      },
      "source": [
        "data = data.iloc[:, 3:]\n",
        "data[data == 'NR'] = 0\n",
        "raw_data = data.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7PCrVwX6jBF"
      },
      "source": [
        "# **Extract Features (1)**\n",
        "![圖片說明](https://drive.google.com/uc?id=1LyaqD4ojX07oe5oDzPO99l9ts5NRyArH)\n",
        "![圖片說明](https://drive.google.com/uc?id=1ZroBarcnlsr85gibeqEF-MtY13xJTG47)\n",
        "\n",
        "將原始 4320 * 18 的資料依照每個月分重組成 12 個 18 (features) * 480 (hours) 的資料。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBnrGYXu9dZQ"
      },
      "source": [
        "month_data = {}\n",
        "for month in range(12):\n",
        "    sample = np.empty([18, 480])\n",
        "    for day in range(20):\n",
        "        sample[:, day * 24 : (day + 1) * 24] = raw_data[18 * (20 * month + day) : 18 * (20 * month + day + 1), :]\n",
        "    month_data[month] = sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhVmtFEQ9D6t"
      },
      "source": [
        "# **Extract Features (2)**\n",
        "![alt text](https://drive.google.com/uc?id=1wKoPuaRHoX682LMiBgIoOP4PDyNKsJLK)\n",
        "![alt text](https://drive.google.com/uc?id=1FRWWiXQ-Qh0i9tyx0LiugHYF_xDdkhLN)\n",
        "\n",
        "每個月會有 480hrs，每 9 小時形成一個 data，每個月會有 471 個 data，故總資料數為 471 * 12 筆，而每筆 data 有 9 * 18 的 features (一小時 18 個 features * 9 小時)。\n",
        "\n",
        "對應的 target 則有 471 * 12 個(第 10 個小時的 PM2.5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcOrC4Fi-n3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e2c76d3-3fff-419f-b7bd-6753353208e7"
      },
      "source": [
        "x = np.empty([12 * 471, 18 * 9], dtype = float)\n",
        "y = np.empty([12 * 471, 1], dtype = float)\n",
        "for month in range(12):\n",
        "    for day in range(20):\n",
        "        for hour in range(24):\n",
        "            if day == 19 and hour > 14:\n",
        "                continue\n",
        "            x[month * 471 + day * 24 + hour, :] = month_data[month][:,day * 24 + hour : day * 24 + hour + 9].reshape(1, -1) #vector dim:18*9 (9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9)\n",
        "            y[month * 471 + day * 24 + hour, 0] = month_data[month][9, day * 24 + hour + 9] #value\n",
        "print(x)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[14.  14.  14.  ...  2.   2.   0.5]\n",
            " [14.  14.  13.  ...  2.   0.5  0.3]\n",
            " [14.  13.  12.  ...  0.5  0.3  0.8]\n",
            " ...\n",
            " [17.  18.  19.  ...  1.1  1.4  1.3]\n",
            " [18.  19.  18.  ...  1.4  1.3  1.6]\n",
            " [19.  18.  17.  ...  1.3  1.6  1.8]]\n",
            "[[30.]\n",
            " [41.]\n",
            " [44.]\n",
            " ...\n",
            " [17.]\n",
            " [24.]\n",
            " [29.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wOii0TX8IwE"
      },
      "source": [
        "# **Normalize (1)**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceMqFoNI8ftQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d3da7e-16f6-4133-e187-605c4b8d2616"
      },
      "source": [
        "mean_x = np.mean(x, axis = 0) #18 * 9 \n",
        "std_x = np.std(x, axis = 0) #18 * 9 \n",
        "for i in range(len(x)): #12 * 471\n",
        "    for j in range(len(x[0])): #18 * 9 \n",
        "        if std_x[j] != 0:\n",
        "            x[i][j] = (x[i][j] - mean_x[j]) / std_x[j]\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.35825331, -1.35883937, -1.359222  , ...,  0.26650729,\n",
              "         0.2656797 , -1.14082131],\n",
              "       [-1.35825331, -1.35883937, -1.51819928, ...,  0.26650729,\n",
              "        -1.13963133, -1.32832904],\n",
              "       [-1.35825331, -1.51789368, -1.67717656, ..., -1.13923451,\n",
              "        -1.32700613, -0.85955971],\n",
              "       ...,\n",
              "       [-0.88092053, -0.72262212, -0.56433559, ..., -0.57693779,\n",
              "        -0.29644471, -0.39079039],\n",
              "       [-0.7218096 , -0.56356781, -0.72331287, ..., -0.29578943,\n",
              "        -0.39013211, -0.1095288 ],\n",
              "       [-0.56269867, -0.72262212, -0.88229015, ..., -0.38950555,\n",
              "        -0.10906991,  0.07797893]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzvXP5Jya64j"
      },
      "source": [
        "#**Split Training Data Into \"train_set\" and \"validation_set\"**\n",
        "這部分是針對作業中 report 的第二題、第三題做的簡單示範，以生成比較中用來訓練的 train_set 和不會被放入訓練、只是用來驗證的 validation_set。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feF4XXOQb5SC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eabaaa64-bd06-4af5-c336-8a7a49f2f39c"
      },
      "source": [
        "import math\n",
        "x_train_set = x[: math.floor(len(x) * 0.8), :]\n",
        "y_train_set = y[: math.floor(len(y) * 0.8), :]\n",
        "x_validation = x[math.floor(len(x) * 0.8): , :]\n",
        "y_validation = y[math.floor(len(y) * 0.8): , :]\n",
        "print(x_train_set)\n",
        "print(y_train_set)\n",
        "print(x_validation)\n",
        "print(y_validation)\n",
        "print(len(x_train_set))\n",
        "print(len(y_train_set))\n",
        "print(len(x_validation))\n",
        "print(len(y_validation))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.35825331 -1.35883937 -1.359222   ...  0.26650729  0.2656797\n",
            "  -1.14082131]\n",
            " [-1.35825331 -1.35883937 -1.51819928 ...  0.26650729 -1.13963133\n",
            "  -1.32832904]\n",
            " [-1.35825331 -1.51789368 -1.67717656 ... -1.13923451 -1.32700613\n",
            "  -0.85955971]\n",
            " ...\n",
            " [ 0.86929969  0.70886668  0.38952809 ...  1.39110073  0.2656797\n",
            "  -0.39079039]\n",
            " [ 0.71018876  0.39075806  0.07157353 ...  0.26650729 -0.39013211\n",
            "  -0.39079039]\n",
            " [ 0.3919669   0.07264944  0.07157353 ... -0.38950555 -0.39013211\n",
            "  -0.85955971]]\n",
            "[[30.]\n",
            " [41.]\n",
            " [44.]\n",
            " ...\n",
            " [ 7.]\n",
            " [ 5.]\n",
            " [14.]]\n",
            "[[ 0.07374504  0.07264944  0.07157353 ... -0.38950555 -0.85856912\n",
            "  -0.57829812]\n",
            " [ 0.07374504  0.07264944  0.23055081 ... -0.85808615 -0.57750692\n",
            "   0.54674825]\n",
            " [ 0.07374504  0.23170375  0.23055081 ... -0.57693779  0.54674191\n",
            "  -0.1095288 ]\n",
            " ...\n",
            " [-0.88092053 -0.72262212 -0.56433559 ... -0.57693779 -0.29644471\n",
            "  -0.39079039]\n",
            " [-0.7218096  -0.56356781 -0.72331287 ... -0.29578943 -0.39013211\n",
            "  -0.1095288 ]\n",
            " [-0.56269867 -0.72262212 -0.88229015 ... -0.38950555 -0.10906991\n",
            "   0.07797893]]\n",
            "[[13.]\n",
            " [24.]\n",
            " [22.]\n",
            " ...\n",
            " [17.]\n",
            " [24.]\n",
            " [29.]]\n",
            "4521\n",
            "4521\n",
            "1131\n",
            "1131\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-qAu0KR_ZRR"
      },
      "source": [
        "# **Training**\n",
        "![alt text](https://drive.google.com/uc?id=1xIXvqZ4EGgmxrp7c9r0LOVbcvd4d9H4N)\n",
        "![alt text](https://drive.google.com/uc?id=1S42g06ON5oJlV2f9RukxawjbE4NpsaB6)\n",
        "![alt text](https://drive.google.com/uc?id=1BbXu-oPB9EZBHDQ12YCkYqtyAIil3bGj)\n",
        "\n",
        "(和上圖不同處: 下面的 code 採用 Root Mean Square Error)\n",
        "\n",
        "因為常數項的存在，所以 dimension (dim) 需要多加一欄；eps 項是避免 adagrad 的分母為 0 而加的極小數值。\n",
        "\n",
        "每一個 dimension (dim) 會對應到各自的 gradient, weight (w)，透過一次次的 iteration (iter_time) 學習。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCzDfxBFBFqp"
      },
      "source": [
        "dim = 18 * 9 + 1\n",
        "w = np.zeros([dim, 1])\n",
        "x = np.concatenate((np.ones([12 * 471, 1]), x), axis = 1).astype(float)\n",
        "learning_rate = 100\n",
        "iter_time = 1000\n",
        "adagrad = np.zeros([dim, 1])\n",
        "eps = 0.0000000001\n",
        "for t in range(iter_time):\n",
        "    loss = np.sqrt(np.sum(np.power(np.dot(x, w) - y, 2))/471/12)#rmse\n",
        "    if(t%100==0):\n",
        "        print(str(t) + \":\" + str(loss))\n",
        "    gradient = 2 * np.dot(x.transpose(), np.dot(x, w) - y) #dim*1\n",
        "    adagrad += gradient ** 2\n",
        "    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
        "np.save('weight.npy', w)\n",
        "w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqNdWKsYBK28"
      },
      "source": [
        "# **Testing**\n",
        "![alt text](https://drive.google.com/uc?id=1165ETzZyE6HStqKvgR0gKrJwgFLK6-CW)\n",
        "\n",
        "載入 test data，並且以相似於訓練資料預先處理和特徵萃取的方式處理，使 test data 形成 240 個維度為 18 * 9 + 1 的資料。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AALygqJFCWOA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "337608ff-2c3d-414c-8c58-b9a19d663950"
      },
      "source": [
        "# testdata = pd.read_csv('gdrive/My Drive/hw1-regression/test.csv', header = None, encoding = 'big5')\n",
        "testdata = pd.read_csv('./test.csv', header = None, encoding = 'big5')\n",
        "test_data = testdata.iloc[:, 2:]\n",
        "test_data[test_data == 'NR'] = 0\n",
        "test_data = test_data.to_numpy()\n",
        "test_x = np.empty([240, 18*9], dtype = float)\n",
        "for i in range(240):\n",
        "    test_x[i, :] = test_data[18 * i: 18* (i + 1), :].reshape(1, -1)\n",
        "for i in range(len(test_x)):\n",
        "    for j in range(len(test_x[0])):\n",
        "        if std_x[j] != 0:\n",
        "            test_x[i][j] = (test_x[i][j] - mean_x[j]) / std_x[j]\n",
        "test_x = np.concatenate((np.ones([240, 1]), test_x), axis = 1).astype(float)\n",
        "test_x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3093: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._where(-key, value, inplace=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.24447681, -0.24545919, ..., -0.67065391,\n",
              "        -1.04594393,  0.07797893],\n",
              "       [ 1.        , -1.35825331, -1.51789368, ...,  0.17279117,\n",
              "        -0.10906991, -0.48454426],\n",
              "       [ 1.        ,  1.5057434 ,  1.34508393, ..., -1.32666675,\n",
              "        -1.04594393, -0.57829812],\n",
              "       ...,\n",
              "       [ 1.        ,  0.3919669 ,  0.54981237, ...,  0.26650729,\n",
              "        -0.20275731,  1.20302531],\n",
              "       [ 1.        , -1.8355861 , -1.8360023 , ..., -1.04551839,\n",
              "        -1.13963133, -1.14082131],\n",
              "       [ 1.        , -1.35825331, -1.35883937, ...,  2.98427476,\n",
              "         3.26367657,  1.76554849]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJQks9JEHR6W"
      },
      "source": [
        "# **Prediction**\n",
        "說明圖同上\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1165ETzZyE6HStqKvgR0gKrJwgFLK6-CW)\n",
        "\n",
        "有了 weight 和測試資料即可預測 target。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNyB229jHsEQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "867f8de5-3470-4b92-ced4-620756461895"
      },
      "source": [
        "w = np.load('weight.npy')\n",
        "ans_y = np.dot(test_x, w)\n",
        "ans_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-6f3df9783732>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weight.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mans_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mans_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'weight.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKMKW7RzHwuO"
      },
      "source": [
        "# **Save Prediction to CSV File**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dwfpqqy0H8en"
      },
      "source": [
        "import csv\n",
        "with open('submit.csv', mode='w', newline='') as submit_file:\n",
        "    csv_writer = csv.writer(submit_file)\n",
        "    header = ['id', 'value']\n",
        "    print(header)\n",
        "    csv_writer.writerow(header)\n",
        "    for i in range(240):\n",
        "        row = ['id_' + str(i), ans_y[i][0]]\n",
        "        csv_writer.writerow(row)\n",
        "        print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y54yWq9cIPR4"
      },
      "source": [
        "相關 reference 可以參考:\n",
        "\n",
        "Adagrad :\n",
        "https://youtu.be/yKKNr-QKz2Q?list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49&t=705 \n",
        "\n",
        "RMSprop : \n",
        "https://www.youtube.com/watch?v=5Yt-obwvMHI \n",
        "\n",
        "Adam\n",
        "https://www.youtube.com/watch?v=JXQT_vxqwIs \n",
        "\n",
        "\n",
        "以上 print 的部分主要是為了看一下資料和結果的呈現，拿掉也無妨。另外，在自己的 linux 系統，可以將檔案寫死的的部分換成 sys.argv 的使用 (可在 terminal 自行輸入檔案和檔案位置)。\n",
        "\n",
        "最後，可以藉由調整 learning rate、iter_time (iteration 次數)、取用 features 的多寡(取幾個小時，取哪些特徵欄位)，甚至是不同的 model 來超越 baseline。\n",
        "\n",
        "Report 的問題模板請參照 : https://docs.google.com/document/d/1s84RXs2AEgZr54WCK9IgZrfTF-6B1td-AlKR9oqYa4g/edit"
      ]
    }
  ]
}